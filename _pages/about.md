---
layout: about
title: About
permalink: /

profile:
  align: right
  image: profile.jpg

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Machine learning is one of the most disruptive technologies of our time. However, a recurring criticism of machine learning is that, in practice, training a model is often more of an art than a science.

The goal of my research is to develop machine learning approaches that can configure themselves automatically by learning from past data. In the long term, I hope that my work will contribute to fulfilling the promise of artificial intelligence and lead to complete end-to-end learning systems.


More specifically, my research interests include:
 - Automated machine learning
 - Neural architecture search
 - Bayesian optimization
 - Resource efficient large language models



### short bio

I am an applied scientist in the long-term science team at AWS SageMaker, where I work on large-scale distributed hyperparameter and architecture search. Prior to that, I was a PhD student at the University of Freiburg under the supervision of [Frank Hutter](http://ml.informatik.uni-freiburg.de/~hutter/). In 2015, my collaborators from the University of Freiburg and I won the ChaLearn AutoML Challenge. I co-organized the workshop on neural architecture search at ICRL 2020 and ICLR 2021, respectively. Together with [Giovanni Zappella](https://giovannizappella.github.io/), [Arber Zela](https://ml.informatik.uni-freiburg.de/people/zela/index.html), and [Jovita Lukasik](https://www.uni-mannheim.de/dws/people/researchers/phd-students/jovita-lukasik/), I run the virtual [AutoML Seminar](https://automl-seminars.github.io/) as part of the ELLIS units in Berlin and Freiburg. I also regularly serve as a reviewer for ICML, ICLR, NeurIPS, TMLR, and JMLR.


